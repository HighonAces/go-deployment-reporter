# k6-load-test.yaml

# 1. ConfigMap with an aggressive k6 test script.
apiVersion: v1
kind: ConfigMap
metadata:
  name: k6-load-test-script
  namespace: go-reporter-ns
data:
  script.js: |
    import http from 'k6/http';
    import { sleep, check } from 'k6';

    export const options = {
        stages: [
            // 1. Ramp-up from 1 to 500 virtual users over 2 minutes
            { duration: '2m', target: 500 },
            // 2. Stay at a high load of 500 virtual users for 5 minutes
            { duration: '5m', target: 500 },
            // 3. Ramp-down to 0 virtual users over 1 minute
            { duration: '1m', target: 0 },
        ],
        thresholds: {
            // Define success criteria: less than 1% of requests should fail.
            'http_req_failed': ['rate<0.01'],
        },
    };

    export default function () {
        const res = http.get('http://go-deployment-reporter-svc.go-reporter-ns.svc.cluster.local/');
        
        check(res, { 'status was 200': (r) => r.status == 200 });
        
        // By removing sleep(), each VU sends requests in a tight loop, maximizing load.
    }

---
# 2. Job to run the k6 load test.
apiVersion: batch/v1
kind: Job
metadata:
  name: go-reporter-load-test
  namespace: go-reporter-ns
spec:
  template:
    spec:
      containers:
        - name: k6
          image: grafana/k6:latest
          command: ["k6", "run", "/scripts/script.js"]
          # Add resource requests/limits for the k6 pod itself
          resources:
            requests:
              cpu: "500m"    # Request 0.5 CPU
              memory: "512Mi"
            limits:
              cpu: "1"       # Allow up to 1 full CPU
              memory: "1Gi"
          volumeMounts:
            - name: k6-script-volume
              mountPath: /scripts
      restartPolicy: Never
      volumes:
        - name: k6-script-volume
          configMap:
            name: k6-load-test-script
  backoffLimit: 4